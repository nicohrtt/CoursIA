{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docteur vs ChatGPT: Chatbot m√©dical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install semantic-kernel openai python-dotenv --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des biblioth√®ques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent, AgentGroupChat\n",
    "from semantic_kernel.agents.strategies import TerminationStrategy\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "from semantic_kernel.functions import kernel_function, KernelArguments\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "from typing import Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger les variables d'environnement\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration des logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des logs\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger('MedicalAI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cr√©ation du kernel Semantic Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation du kernel Semantic Kernel\n",
    "def create_kernel():\n",
    "    kernel = Kernel()\n",
    "    kernel.add_service(OpenAIChatCompletion(\n",
    "        service_id=\"openai\",\n",
    "        ai_model_id=\"gpt-4o-mini\",  # Modifier si besoin\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "    ))\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D√©finition des plugins √† chaque agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoctorPlugin:\n",
    "    \"\"\"Plugin permettant au m√©decin de poser des questions compl√©mentaires sur les sympt√¥mes.\"\"\"\n",
    "    @kernel_function(description=\"Pose des questions suppl√©mentaires pour affiner le diagnostic.\")\n",
    "    def ask_followup_questions(self, symptom: Annotated[str, \"Sympt√¥me d√©crit par l'utilisateur\"]) -> str:\n",
    "        \"\"\"Retourne une question en fonction du sympt√¥me mentionn√©.\"\"\"\n",
    "        questions_map = {\n",
    "            \"fi√®vre\": \"Depuis combien de temps avez-vous de la fi√®vre ?\",\n",
    "            \"maux de t√™te\": \"Avez-vous une sensibilit√© √† la lumi√®re ou au bruit ?\",\n",
    "            \"douleur thoracique\": \"La douleur est-elle aigu√´ ou diffuse ?\",\n",
    "        }\n",
    "        return questions_map.get(symptom.lower(), \"Pouvez-vous donner plus de d√©tails sur vos sympt√¥mes ?\")\n",
    "\n",
    "class MedicalAIPlugin:\n",
    "    \"\"\"Plugin qui analyse la gravit√© des sympt√¥mes.\"\"\"\n",
    "    @kernel_function(description=\"V√©rifie la gravit√© d'un sympt√¥me m√©dical.\")\n",
    "    def check_symptom_severity(self, symptom: Annotated[str, \"Sympt√¥me d√©crit par l'utilisateur\"]) -> str:\n",
    "        \"\"\"Retourne une √©valuation de la gravit√© du sympt√¥me.\"\"\"\n",
    "        severity_map = {\n",
    "            \"fi√®vre\": \"Mod√©r√©e\",\n",
    "            \"maux de t√™te\": \"L√©ger\",\n",
    "            \"douleur thoracique\": \"S√©v√®re\",\n",
    "            \"perte de connaissance\": \"Critique\"\n",
    "        }\n",
    "        return severity_map.get(symptom.lower(), \"Inconnu - consultez un m√©decin.\")\n",
    "\n",
    "class PharmacistPlugin:\n",
    "    \"\"\"Plugin qui recommande des m√©dicaments en fonction du diagnostic.\"\"\"\n",
    "    @kernel_function(description=\"Recommande un m√©dicament adapt√© √† un sympt√¥me.\")\n",
    "    def recommend_medication(self, symptom: Annotated[str, \"Sympt√¥me d√©crit par l'utilisateur\"]) -> str:\n",
    "        \"\"\"Retourne une suggestion de m√©dicament (avec pr√©cautions).\"\"\"\n",
    "        medication_map = {\n",
    "            \"fi√®vre\": \"Parac√©tamol (500mg, toutes les 6h, max 3 jours)\",\n",
    "            \"maux de t√™te\": \"Ibuprof√®ne (200mg, toutes les 8h, avec pr√©caution si probl√®me gastrique)\",\n",
    "            \"douleur thoracique\": \"Aucun m√©dicament recommand√© - Consultez un m√©decin imm√©diatement\",\n",
    "        }\n",
    "        return medication_map.get(symptom.lower(), \"Aucun m√©dicament recommand√© - Consultez un pharmacien.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cr√©ation du Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation du kernel\n",
    "kernel = create_kernel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajout des plugins pour chaque agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='pharmacist', description=None, functions={'recommend_medication': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='recommend_medication', plugin_name='pharmacist', description='Recommande un m√©dicament adapt√© √† un sympt√¥me.', parameters=[KernelParameterMetadata(name='symptom', description=\"Sympt√¥me d√©crit par l'utilisateur\", default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string', 'description': \"Sympt√¥me d√©crit par l'utilisateur\"}, include_in_function_choices=True)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x116ecd460>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x116ecc950>, method=<bound method PharmacistPlugin.recommend_medication of <__main__.PharmacistPlugin object at 0x10f4b8a40>>, stream_method=None)})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajout des plugins pour chaque agent\n",
    "kernel.add_plugin(DoctorPlugin(), plugin_name=\"doctor\")\n",
    "kernel.add_plugin(MedicalAIPlugin(), plugin_name=\"medical\")\n",
    "kernel.add_plugin(PharmacistPlugin(), plugin_name=\"pharmacist\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D√©finition des prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCTOR_PROMPT = \"\"\"\n",
    "Vous √™tes un m√©decin g√©n√©raliste. Vous posez d'abord des questions pour mieux comprendre les sympt√¥mes de l'utilisateur,\n",
    "puis vous donnez un diagnostic probable bas√© sur votre expertise m√©dicale. \n",
    "Ne donnez jamais de diagnostic sans avoir recueilli assez d'informations.\n",
    "\"\"\"\n",
    "\n",
    "AI_MEDICAL_PROMPT = \"\"\"\n",
    "Vous √™tes une IA m√©dicale sp√©cialis√©e en diagnostic. Analysez les sympt√¥mes fournis et proposez un diagnostic bas√© sur des statistiques et des √©tudes m√©dicales. \n",
    "Soyez clair et donnez plusieurs hypoth√®ses si n√©cessaire.\n",
    "\"\"\"\n",
    "\n",
    "PHARMACIST_PROMPT = \"\"\"\n",
    "Vous √™tes un pharmacien qualifi√©. En fonction du diagnostic fourni, vous recommandez les m√©dicaments appropri√©s. \n",
    "Mentionnez toujours les pr√©cautions d'utilisation et la n√©cessit√© d'une consultation m√©dicale avant la prise de m√©dicaments.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cr√©ation des agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation des agents\n",
    "doctor_agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    service_id=\"openai\",\n",
    "    name=\"Docteur_Humain\",\n",
    "    instructions=DOCTOR_PROMPT,\n",
    ")\n",
    "\n",
    "ai_medical_agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    service_id=\"openai\",\n",
    "    name=\"IA_Medicale\",\n",
    "    instructions=AI_MEDICAL_PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration pour que l'agent m√©dical appelle automatiquement les plugins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = kernel.get_prompt_execution_settings_from_service_id(\"openai\")\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "ai_medical_agent.arguments = KernelArguments(settings=settings)\n",
    "\n",
    "pharmacist_agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    service_id=\"openai\",\n",
    "    name=\"Pharmacien\",\n",
    "    instructions=PHARMACIST_PROMPT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D√©finition d'une strat√©gie de terminaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalTerminationStrategy(TerminationStrategy):\n",
    "    async def should_terminate(self, agent, history):\n",
    "        return len(history) >= 6  # On limite √† 6 √©changes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cr√©ation du chat group√© avec strat√©gie de terminaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = AgentGroupChat(\n",
    "    agents=[doctor_agent, ai_medical_agent, pharmacist_agent],\n",
    "    termination_strategy=MedicalTerminationStrategy()  # Ajout de la strat√©gie\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction pour ex√©cuter le dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_medical_chat():\n",
    "    logger.info(\"üöÄ D√©but de la consultation m√©dicale IA\")\n",
    "    chat_history = ChatHistory()\n",
    "    \n",
    "    symptoms = input(\"D√©crivez vos sympt√¥mes : \")\n",
    "    chat_history.add_user_message(symptoms)\n",
    "    \n",
    "    while True:\n",
    "        async for message in chat.invoke():\n",
    "            logger.info(f\"[{message.role}] {message.name}: {message.content}\")\n",
    "            print(f\"{message.name}: {message.content}\")\n",
    "            \n",
    "            if message.name not in [\"Pharmacien\"]:\n",
    "                user_response = input(\"üëâ Votre r√©ponse : \")\n",
    "                chat_history.add_user_message(user_response)\n",
    "        \n",
    "        if chat.is_complete:\n",
    "            break\n",
    "    \n",
    "    logger.info(\"üè• Consultation termin√©e.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 09:38:10,977 [INFO] üöÄ D√©but de la consultation m√©dicale IA\n"
     ]
    }
   ],
   "source": [
    "await run_medical_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
